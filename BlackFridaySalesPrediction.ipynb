{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BlackFridaySalesPrediction.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM0qmlmIyePUUck1Mj+cEjq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lhr8RbXkI3NY"},"outputs":[],"source":["import library\n","# manipulation data\n","import pandas as pd\n","import numpy as np\n","\n","#visualiation data\n","import matplotlib.pyplot as plt\n","import seaborn as sns \n","import matplotlib\n","import plotly.graph_objects as go\n","import plotly.express as px\n","from plotly.subplots import make_subplots\n","from plotly.offline import init_notebook_mode, iplot\n","\n","#default theme\n","plt.style.use('ggplot')\n","sns.set(context='notebook', style='darkgrid', palette='colorblind', font='sans-serif', font_scale=1, rc=None)\n","matplotlib.rcParams['figure.figsize'] =[8,8]\n","matplotlib.rcParams.update({'font.size': 15})\n","matplotlib.rcParams['font.family'] = 'sans-serif'\n","2. data analysis\n","train = pd.read_csv('../input/black-friday/train.csv')\n","test = pd.read_csv('../input/black-friday/test.csv')\n","train.head(5)\n","User_ID\tProduct_ID\tGender\tAge\tOccupation\tCity_Category\tStay_In_Current_City_Years\tMarital_Status\tProduct_Category_1\tProduct_Category_2\tProduct_Category_3\tPurchase\n","0\t1000001\tP00069042\tF\t0-17\t10\tA\t2\t0\t3\tNaN\tNaN\t8370\n","1\t1000001\tP00248942\tF\t0-17\t10\tA\t2\t0\t1\t6.0\t14.0\t15200\n","2\t1000001\tP00087842\tF\t0-17\t10\tA\t2\t0\t12\tNaN\tNaN\t1422\n","3\t1000001\tP00085442\tF\t0-17\t10\tA\t2\t0\t12\t14.0\tNaN\t1057\n","4\t1000002\tP00285442\tM\t55+\t16\tC\t4+\t0\t8\tNaN\tNaN\t7969\n","train.shape\n","(550068, 12)\n","like we c her we had\n","\n","550068 rows\n","12 coluns\n","train.info()\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 550068 entries, 0 to 550067\n","Data columns (total 12 columns):\n"," #   Column                      Non-Null Count   Dtype  \n","---  ------                      --------------   -----  \n"," 0   User_ID                     550068 non-null  int64  \n"," 1   Product_ID                  550068 non-null  object \n"," 2   Gender                      550068 non-null  object \n"," 3   Age                         550068 non-null  object \n"," 4   Occupation                  550068 non-null  int64  \n"," 5   City_Category               550068 non-null  object \n"," 6   Stay_In_Current_City_Years  550068 non-null  object \n"," 7   Marital_Status              550068 non-null  int64  \n"," 8   Product_Category_1          550068 non-null  int64  \n"," 9   Product_Category_2          376430 non-null  float64\n"," 10  Product_Category_3          166821 non-null  float64\n"," 11  Purchase                    550068 non-null  int64  \n","dtypes: float64(2), int64(5), object(5)\n","memory usage: 50.4+ MB\n","train.dtypes.value_counts().plot.pie(explode=[0.1,0.1,0.1],autopct='%1.2f%%',shadow=True)\n","plt.title('type of our data');\n","\n","# show the numirical values\n","\n","num_columns = [f for f in train.columns if train.dtypes[f] != 'object']\n","num_columns.remove('Purchase')\n","num_columns.remove('User_ID')\n","num_columns\n","['Occupation',\n"," 'Marital_Status',\n"," 'Product_Category_1',\n"," 'Product_Category_2',\n"," 'Product_Category_3']\n","# show the categorical values\n","\n","cat_columns = [f for f in train.columns if train.dtypes[f] == 'object']\n","cat_columns\n","['Product_ID', 'Gender', 'Age', 'City_Category', 'Stay_In_Current_City_Years']\n","train.describe(include='all')\n","User_ID\tProduct_ID\tGender\tAge\tOccupation\tCity_Category\tStay_In_Current_City_Years\tMarital_Status\tProduct_Category_1\tProduct_Category_2\tProduct_Category_3\tPurchase\n","count\t5.500680e+05\t550068\t550068\t550068\t550068.000000\t550068\t550068\t550068.000000\t550068.000000\t376430.000000\t166821.000000\t550068.000000\n","unique\tNaN\t3631\t2\t7\tNaN\t3\t5\tNaN\tNaN\tNaN\tNaN\tNaN\n","top\tNaN\tP00265242\tM\t26-35\tNaN\tB\t1\tNaN\tNaN\tNaN\tNaN\tNaN\n","freq\tNaN\t1880\t414259\t219587\tNaN\t231173\t193821\tNaN\tNaN\tNaN\tNaN\tNaN\n","mean\t1.003029e+06\tNaN\tNaN\tNaN\t8.076707\tNaN\tNaN\t0.409653\t5.404270\t9.842329\t12.668243\t9263.968713\n","std\t1.727592e+03\tNaN\tNaN\tNaN\t6.522660\tNaN\tNaN\t0.491770\t3.936211\t5.086590\t4.125338\t5023.065394\n","min\t1.000001e+06\tNaN\tNaN\tNaN\t0.000000\tNaN\tNaN\t0.000000\t1.000000\t2.000000\t3.000000\t12.000000\n","25%\t1.001516e+06\tNaN\tNaN\tNaN\t2.000000\tNaN\tNaN\t0.000000\t1.000000\t5.000000\t9.000000\t5823.000000\n","50%\t1.003077e+06\tNaN\tNaN\tNaN\t7.000000\tNaN\tNaN\t0.000000\t5.000000\t9.000000\t14.000000\t8047.000000\n","75%\t1.004478e+06\tNaN\tNaN\tNaN\t14.000000\tNaN\tNaN\t1.000000\t8.000000\t15.000000\t16.000000\t12054.000000\n","max\t1.006040e+06\tNaN\tNaN\tNaN\t20.000000\tNaN\tNaN\t1.000000\t20.000000\t18.000000\t18.000000\t23961.000000\n","A basic observation is that:\n","\n","Product P00265242 is the most popular product.\n","Most of the transactions were made by men.\n","Age group with most transactions was 26-35.\n","City Category with most transactions was B\n","but we will cover each of these in more depth later\n","\n","finding missing values\n","missing_values=train.isnull().sum()\n","percent_missing = train.isnull().sum()/train.shape[0]*100\n","\n","value = {\n","    'missing_values':missing_values,\n","    'percent_missing':percent_missing\n","}\n","frame=pd.DataFrame(value)\n","frame\n","missing_values\tpercent_missing\n","User_ID\t0\t0.000000\n","Product_ID\t0\t0.000000\n","Gender\t0\t0.000000\n","Age\t0\t0.000000\n","Occupation\t0\t0.000000\n","City_Category\t0\t0.000000\n","Stay_In_Current_City_Years\t0\t0.000000\n","Marital_Status\t0\t0.000000\n","Product_Category_1\t0\t0.000000\n","Product_Category_2\t173638\t31.566643\n","Product_Category_3\t383247\t69.672659\n","Purchase\t0\t0.000000\n","missing_values = train.isnull().sum()\n","missing_values = missing_values[missing_values > 0]\n","missing_values.sort_values(inplace=True)\n","missing_values.plot.pie(explode=[0.1,0.1],autopct='%1.1f%%',shadow=True)\n","plt.title('our missing values');\n","\n","Only Product_Category_2 and Product_Category_3 have null values which is good news. However Product_Category_3 is null for nearly 70% of transactions so it can't give us much information. so we gonna drop Product_Category_3\n","\n","Product_Category_2\n","train.Product_Category_2.value_counts()\n","8.0     64088\n","14.0    55108\n","2.0     49217\n","16.0    43255\n","15.0    37855\n","5.0     26235\n","4.0     25677\n","6.0     16466\n","11.0    14134\n","17.0    13320\n","13.0    10531\n","9.0      5693\n","12.0     5528\n","10.0     3043\n","3.0      2884\n","18.0     2770\n","7.0       626\n","Name: Product_Category_2, dtype: int64\n","train.Product_Category_2.describe()\n","count    376430.000000\n","mean          9.842329\n","std           5.086590\n","min           2.000000\n","25%           5.000000\n","50%           9.000000\n","75%          15.000000\n","max          18.000000\n","Name: Product_Category_2, dtype: float64\n","# Replace using median \n","median = train['Product_Category_2'].median()\n","train['Product_Category_2'].fillna(median, inplace=True)\n","Product_Category_3\n","train.Product_Category_3.value_counts()\n","16.0    32636\n","15.0    28013\n","14.0    18428\n","17.0    16702\n","5.0     16658\n","8.0     12562\n","9.0     11579\n","12.0     9246\n","13.0     5459\n","6.0      4890\n","18.0     4629\n","4.0      1875\n","11.0     1805\n","10.0     1726\n","3.0       613\n","Name: Product_Category_3, dtype: int64\n","# drop Product_Category_3 \n","train=train.drop('Product_Category_3',axis=1)\n","missing_values=train.isnull().sum()\n","percent_missing = train.isnull().sum()/train.shape[0]*100\n","\n","value = {\n","    'missing_values':missing_values,\n","    'percent_missing':percent_missing\n","}\n","frame=pd.DataFrame(value)\n","frame\n","missing_values\tpercent_missing\n","User_ID\t0\t0.0\n","Product_ID\t0\t0.0\n","Gender\t0\t0.0\n","Age\t0\t0.0\n","Occupation\t0\t0.0\n","City_Category\t0\t0.0\n","Stay_In_Current_City_Years\t0\t0.0\n","Marital_Status\t0\t0.0\n","Product_Category_1\t0\t0.0\n","Product_Category_2\t0\t0.0\n","Purchase\t0\t0.0\n","3. data visualization\n","train.hist(edgecolor='black',figsize=(12,12));\n","\n","train.columns\n","Index(['User_ID', 'Product_ID', 'Gender', 'Age', 'Occupation', 'City_Category',\n","       'Stay_In_Current_City_Years', 'Marital_Status', 'Product_Category_1',\n","       'Product_Category_2', 'Purchase'],\n","      dtype='object')\n","A) Gender\n","# pie chart \n","\n","size = train['Gender'].value_counts()\n","labels = ['Male', 'Female']\n","colors = ['#C4061D', 'green']\n","explode = [0, 0.1]\n","\n","plt.rcParams['figure.figsize'] = (10, 10)\n","plt.pie(size, colors = colors, labels = labels, shadow = True, explode = explode, autopct = '%.2f%%')\n","plt.title('A Pie Chart representing the gender gap', fontsize = 20)\n","plt.axis('off')\n","plt.legend()\n","plt.show()\n","\n","sns.countplot(x=train.Gender)\n","plt.title('Gender per transaction');\n","\n","B) Age\n","ageData = sorted(list(zip(train.Age.value_counts().index, train.Age.value_counts().values)))\n","age, productBuy = zip(*ageData)\n","age, productBuy = list(age), list(productBuy)\n","ageSeries = pd.Series((i for i in age))\n","\n","data = [go.Bar(x=age, \n","               y=productBuy, \n","               name=\"How many products were sold\",\n","               marker = dict(color=['black', 'yellow', 'green', 'blue', 'red', 'gray', '#C4061D'],\n","                            line = dict(color='#7C7C7C', width = .5)),\n","              text=\"Age: \" + ageSeries)]\n","layout = go.Layout(title= \"How many products were sold by ages\")\n","fig = go.Figure(data=data, layout=layout)\n","iplot(fig)\n","C) the occupation of customers\n","palette=sns.color_palette(\"Set2\")\n","plt.rcParams['figure.figsize'] = (18, 9)\n","sns.countplot(train['Occupation'], palette = palette)\n","plt.title('Distribution of Occupation across customers', fontsize = 20)\n","plt.xlabel('Occupation')\n","plt.ylabel('Count')\n","plt.show()\n","/opt/conda/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning:\n","\n","Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","\n","\n","Total Money Spent per Occupation\n","spent_by_occ = train.groupby(by='Occupation').sum()['Purchase']\n","plt.figure(figsize=(20, 7))\n","\n","sns.barplot(x=spent_by_occ.index,y=spent_by_occ.values)\n","plt.title('Total Money Spent per Occupation')\n","plt.show()\n","\n","Once again, the distribution of the mean amount spent within each occupation appears to mirror the distribution of the amount of people within each occupation. This is fortunate from a data science perspective, as we are not working with odd or outstanding features. Our data, in terms of age and occupation seems to simply make sense.\n","\n","d) City_Category\n","plt.rcParams['figure.figsize'] = (18, 9)\n","sns.countplot(train['City_Category'], palette = palette)\n","plt.title('Distribution of Cities across customers', fontsize = 20)\n","plt.xlabel('Cities')\n","plt.ylabel('Count')\n","plt.show()\n","/opt/conda/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning:\n","\n","Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","\n","\n","E) Products\n","Here we explore the products themselves. This is important, as we do not have labeled items in this dataset. Theoretically, a customer could be spending $5,000 on 4 new TVs, or 10,000 pens. This difference matters for stores, as their profits are affected. Since we do not know what the items are, let's explore the categories of the items.\n","\n","plt.figure(figsize=(20,6))\n","prod_by_cat = train.groupby('Product_Category_1')['Product_ID'].nunique()\n","\n","sns.barplot(x=prod_by_cat.index,y=prod_by_cat.values, palette=palette)\n","plt.title('Number of Unique Items per Category')\n","plt.show()\n","\n","Category labels 1, 5, and 8 clearly have the most items within them. This could mean the store is known for that item, or that the category is a broad one.\n","\n","category = []\n","mean_purchase = []\n","\n","\n","for i in train['Product_Category_1'].unique():\n","    category.append(i)\n","category.sort()\n","\n","for e in category:\n","    mean_purchase.append(train[train['Product_Category_1']==e]['Purchase'].mean())\n","\n","plt.figure(figsize=(20,6))\n","\n","sns.barplot(x=category,y=mean_purchase)\n","plt.title('Mean of the Purchases per Category')\n","plt.xlabel('Product Category')\n","plt.ylabel('Mean Purchase')\n","plt.show()\n","\n","# visualizing the different product categories\n","\n","plt.rcParams['figure.figsize'] = (15, 25)\n","plt.style.use('ggplot')\n","\n","plt.subplot(4, 1, 1)\n","sns.countplot(train['Product_Category_1'], palette = palette)\n","plt.title('Product Category 1', fontsize = 20)\n","plt.xlabel('Distribution of Product Category 1')\n","plt.ylabel('Count')\n","\n","plt.subplot(4, 1, 2)\n","sns.countplot(train['Product_Category_2'], palette = palette)\n","plt.title('Product Category 2', fontsize = 20)\n","plt.xlabel('Distribution of Product Category 2')\n","plt.ylabel('Count')\n","\n","\n","plt.show()\n","/opt/conda/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning:\n","\n","Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","\n","/opt/conda/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning:\n","\n","Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","\n","\n","the purchase attribute which is our target variable\n","# importing important libraries\n","from scipy import stats\n","from scipy.stats import norm\n","# plotting a distribution plot for the target variable\n","plt.rcParams['figure.figsize'] = (20, 7)\n","sns.distplot(train['Purchase'], color = 'green', fit = norm)\n","\n","# fitting the target variable to the normal curve \n","mu, sigma = norm.fit(train['Purchase']) \n","print(\"The mu {} and Sigma {} for the curve\".format(mu, sigma))\n","\n","plt.title('A distribution plot to represent the distribution of Purchase')\n","plt.legend(['Normal Distribution ($mu$: {}, $sigma$: {}'.format(mu, sigma)], loc = 'best')\n","plt.show()\n","/opt/conda/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning:\n","\n","`distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n","\n","The mu 9263.968712959126 and Sigma 5023.060827959928 for the curve\n","\n","data selection\n","first we gonna drop the :\n","\n","User_ID\n","Product_ID\n","train = train.drop(['Product_ID','User_ID'],axis=1)\n","# checking the new shape of data\n","print(train.shape)\n","train\n","(550068, 9)\n","Gender\tAge\tOccupation\tCity_Category\tStay_In_Current_City_Years\tMarital_Status\tProduct_Category_1\tProduct_Category_2\tPurchase\n","0\tF\t0-17\t10\tA\t2\t0\t3\t9.0\t8370\n","1\tF\t0-17\t10\tA\t2\t0\t1\t6.0\t15200\n","2\tF\t0-17\t10\tA\t2\t0\t12\t9.0\t1422\n","3\tF\t0-17\t10\tA\t2\t0\t12\t14.0\t1057\n","4\tM\t55+\t16\tC\t4+\t0\t8\t9.0\t7969\n","...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n","550063\tM\t51-55\t13\tB\t1\t1\t20\t9.0\t368\n","550064\tF\t26-35\t1\tC\t3\t0\t20\t9.0\t371\n","550065\tF\t26-35\t15\tB\t4+\t1\t20\t9.0\t137\n","550066\tF\t55+\t1\tC\t2\t0\t20\t9.0\t365\n","550067\tF\t46-50\t0\tB\t4+\t1\t20\t9.0\t490\n","550068 rows × 9 columns\n","\n","label encoding\n","df_Gender = pd.get_dummies(train['Gender'])\n","df_Age = pd.get_dummies(train['Age'])\n","df_City_Category = pd.get_dummies(train['City_Category'])\n","df_Stay_In_Current_City_Years = pd.get_dummies(train['Stay_In_Current_City_Years'])\n","\n","data_final= pd.concat([train, df_Gender, df_Age, df_City_Category, df_Stay_In_Current_City_Years], axis=1)\n","\n","data_final.head()\n","Gender\tAge\tOccupation\tCity_Category\tStay_In_Current_City_Years\tMarital_Status\tProduct_Category_1\tProduct_Category_2\tPurchase\tF\t...\t51-55\t55+\tA\tB\tC\t0\t1\t2\t3\t4+\n","0\tF\t0-17\t10\tA\t2\t0\t3\t9.0\t8370\t1\t...\t0\t0\t1\t0\t0\t0\t0\t1\t0\t0\n","1\tF\t0-17\t10\tA\t2\t0\t1\t6.0\t15200\t1\t...\t0\t0\t1\t0\t0\t0\t0\t1\t0\t0\n","2\tF\t0-17\t10\tA\t2\t0\t12\t9.0\t1422\t1\t...\t0\t0\t1\t0\t0\t0\t0\t1\t0\t0\n","3\tF\t0-17\t10\tA\t2\t0\t12\t14.0\t1057\t1\t...\t0\t0\t1\t0\t0\t0\t0\t1\t0\t0\n","4\tM\t55+\t16\tC\t4+\t0\t8\t9.0\t7969\t0\t...\t0\t1\t0\t0\t1\t0\t0\t0\t0\t1\n","5 rows × 26 columns\n","\n","data_final = data_final.drop(['Gender','Age','City_Category','Stay_In_Current_City_Years'],axis=1)\n","data_final\n","Occupation\tMarital_Status\tProduct_Category_1\tProduct_Category_2\tPurchase\tF\tM\t0-17\t18-25\t26-35\t...\t51-55\t55+\tA\tB\tC\t0\t1\t2\t3\t4+\n","0\t10\t0\t3\t9.0\t8370\t1\t0\t1\t0\t0\t...\t0\t0\t1\t0\t0\t0\t0\t1\t0\t0\n","1\t10\t0\t1\t6.0\t15200\t1\t0\t1\t0\t0\t...\t0\t0\t1\t0\t0\t0\t0\t1\t0\t0\n","2\t10\t0\t12\t9.0\t1422\t1\t0\t1\t0\t0\t...\t0\t0\t1\t0\t0\t0\t0\t1\t0\t0\n","3\t10\t0\t12\t14.0\t1057\t1\t0\t1\t0\t0\t...\t0\t0\t1\t0\t0\t0\t0\t1\t0\t0\n","4\t16\t0\t8\t9.0\t7969\t0\t1\t0\t0\t0\t...\t0\t1\t0\t0\t1\t0\t0\t0\t0\t1\n","...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n","550063\t13\t1\t20\t9.0\t368\t0\t1\t0\t0\t0\t...\t1\t0\t0\t1\t0\t0\t1\t0\t0\t0\n","550064\t1\t0\t20\t9.0\t371\t1\t0\t0\t0\t1\t...\t0\t0\t0\t0\t1\t0\t0\t0\t1\t0\n","550065\t15\t1\t20\t9.0\t137\t1\t0\t0\t0\t1\t...\t0\t0\t0\t1\t0\t0\t0\t0\t0\t1\n","550066\t1\t0\t20\t9.0\t365\t1\t0\t0\t0\t0\t...\t0\t1\t0\t0\t1\t0\t0\t1\t0\t0\n","550067\t0\t1\t20\t9.0\t490\t1\t0\t0\t0\t0\t...\t0\t0\t0\t1\t0\t0\t0\t0\t0\t1\n","550068 rows × 22 columns\n","\n","data_final.dtypes\n","Occupation              int64\n","Marital_Status          int64\n","Product_Category_1      int64\n","Product_Category_2    float64\n","Purchase                int64\n","F                       uint8\n","M                       uint8\n","0-17                    uint8\n","18-25                   uint8\n","26-35                   uint8\n","36-45                   uint8\n","46-50                   uint8\n","51-55                   uint8\n","55+                     uint8\n","A                       uint8\n","B                       uint8\n","C                       uint8\n","0                       uint8\n","1                       uint8\n","2                       uint8\n","3                       uint8\n","4+                      uint8\n","dtype: object\n","Predicting the Amount Spent\n","we will use one of the simplest machine learning models, i.e. the linear regression model, to predict the amount spent by the customer on Black Friday.\n","\n","Linear regression represents a very simple method for supervised learning and it is an effective tool for predicting quantitative responses. You can find basic information about it right here: Linear Regression in Python\n","\n","This model, like most of the supervised machine learning algorithms, makes a prediction based on the input features. The predicted output values are used for comparisons with desired outputs and an error is calculated. The error signal is propagated back through the model and model parameters are updating in a way to minimize the error. Finally, the model is considered to be fully trained if the error is small enough. This is a very basic explanation and we are going to analyze all these processes in details in future articles.\n","\n","split data\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics\n","from sklearn.metrics import accuracy_score\n","x=data_final.drop('Purchase',axis=1)\n","y=data_final.Purchase\n","print(x.shape)\n","print(y.shape)\n","(550068, 21)\n","(550068,)\n","x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25)\n","Feature Scaling\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","x_train = sc.fit_transform(x_train)\n","x_test = sc.transform(x_test)\n","1) LinearRegression\n","from sklearn.linear_model import LinearRegression\n","\n","lm = LinearRegression()\n","lm.fit(x_train, y_train)\n","print(lm.fit(x_train, y_train))\n","LinearRegression()\n","LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n","         normalize=False)\n","LinearRegression()\n","print('Intercept parameter:', lm.intercept_)\n","coeff_df = pd.DataFrame(lm.coef_, x.columns, columns=['Coefficient'])\n","print(coeff_df)\n","Intercept parameter: 9257.575594764789\n","                     Coefficient\n","Occupation          5.223510e+01\n","Marital_Status     -2.568989e+01\n","Product_Category_1 -1.684264e+03\n","Product_Category_2 -2.237834e+02\n","F                  -9.986262e+15\n","M                  -9.986262e+15\n","0-17                1.963183e+16\n","18-25               4.629233e+16\n","26-35               5.886201e+16\n","36-45               4.811073e+16\n","46-50               3.309655e+16\n","51-55               3.064330e+16\n","55+                 2.329971e+16\n","A                  -1.649574e+16\n","B                  -1.836382e+16\n","C                  -1.723161e+16\n","0                  -4.848421e+15\n","1                  -6.770243e+15\n","2                  -5.505961e+15\n","3                  -5.355041e+15\n","4+                 -5.111208e+15\n","predictions = lm.predict(x_test)\n","print(\"Predicted purchases (in dollars) for new costumers:\", predictions)\n","Predicted purchases (in dollars) for new costumers: [ 9382.07559476  9324.07559476  3695.57559476 ...  9590.57559476\n"," 10886.57559476 11560.07559476]\n","from sklearn import metrics\n","\n","print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n","print('MSE:', metrics.mean_squared_error(y_test, predictions))\n","MAE: 3584.9542360607325\n","MSE: 22034268.874539897"]}]}